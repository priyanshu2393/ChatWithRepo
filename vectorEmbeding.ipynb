{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d233c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyanshu\\AppData\\Local\\Temp\\ipykernel_13356\\3130160876.py:58: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n",
      "c:\\Users\\Priyanshu\\Desktop\\GithubAi\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 27.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'name': 'get_db', 'type': 'function', 'file': 'database.py', 'module': 'database', 'start_line': 14, 'end_line': 19}, page_content='function `get_db` in module `database`:\\n\\ndef get_db():\\n    db = SessionLocal()\\n    try:\\n        yield db\\n    finally:\\n        db.close()'), Document(metadata={'name': 'get_current_user', 'type': 'function', 'file': 'authmiddleware.py', 'module': 'auth.authmiddleware', 'start_line': 14, 'end_line': 39}, page_content='function `get_current_user` in module `auth.authmiddleware`:\\n\\ndef get_current_user(\\n    token: str = Depends(oauth2_scheme),\\n    db: Session = Depends(get_db)   # Add DB session\\n) -> DBUser:\\n    payload = verify_access_token(token)\\n    if payload is None:\\n        raise HTTPException(\\n            status_code=status.HTTP_401_UNAUTHORIZED,\\n            detail=\"Invalid or expired token\",\\n            headers={\"WWW-Authenticate\": \"Bearer\"},\\n        )\\n    username = payload.get(\"sub\")\\n    if username is None:\\n        raise HTTPException(\\n            status_code=status.HTTP_401_UNAUTHORIZED,\\n            detail=\"Invalid token payload\",\\n            headers={\"WWW-Authenticate\": \"Bearer\"},\\n        )\\n    user = db.query(DBUser).filter(DBUser.username == username).first()\\n    if user is None:\\n        raise HTTPException(\\n            status_code=status.HTTP_401_UNAUTHORIZED,\\n            detail=\"User not found\",\\n            headers={\"WWW-Authenticate\": \"Bearer\"},\\n        )\\n    return user'), Document(metadata={'name': 'User', 'type': 'class', 'file': 'dbmodel.py', 'module': 'auth.dbmodel', 'start_line': 6, 'end_line': 15}, page_content='class `User` in module `auth.dbmodel`:\\n\\nclass User(Base):\\n    __tablename__ = \"users\"\\n\\n    id = Column(Integer, primary_key=True, index=True)\\n    username = Column(String,  nullable=False, index=True)\\n    email = Column(String, unique=True, index=True, nullable=False)\\n    hashed_password = Column(String, nullable=False)\\n    created_at = Column(DateTime, default=datetime.utcnow)\\n\\n    videos = relationship(\"Video\", back_populates=\"owner\")'), Document(metadata={'name': 'Video', 'type': 'class', 'file': 'dbmodel.py', 'module': 'auth.dbmodel', 'start_line': 18, 'end_line': 29}, page_content='class `Video` in module `auth.dbmodel`:\\n\\nclass Video(Base):\\n    __tablename__ = \"videos\"\\n\\n    id = Column(Integer, primary_key=True, index=True)\\n    title = Column(String, nullable=False)\\n    scene_plan = Column(String)\\n    manim_code = Column(String)\\n    video_path = Column(String)\\n    created_at = Column(DateTime, default=datetime.utcnow)\\n\\n    user_id = Column(Integer, ForeignKey(\"users.id\"))\\n    owner = relationship(\"User\", back_populates=\"videos\")'), Document(metadata={'name': 'create_access_token', 'type': 'function', 'file': 'jwtToken.py', 'module': 'auth.jwtToken', 'start_line': 9, 'end_line': 14}, page_content='function `create_access_token` in module `auth.jwtToken`:\\n\\ndef create_access_token(data: dict, expires_delta: Optional[timedelta] = None):\\n    to_encode = data.copy()\\n    expire = datetime.utcnow() + (expires_delta or timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES))\\n    to_encode.update({\"exp\": expire})\\n    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)\\n    return encoded_jwt'), Document(metadata={'name': 'verify_access_token', 'type': 'function', 'file': 'jwtToken.py', 'module': 'auth.jwtToken', 'start_line': 16, 'end_line': 21}, page_content='function `verify_access_token` in module `auth.jwtToken`:\\n\\ndef verify_access_token(token: str):\\n    try:\\n        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\\n        return payload\\n    except JWTError:\\n        return None'), Document(metadata={'name': 'get_password_hash', 'type': 'function', 'file': 'routes.py', 'module': 'auth.routes', 'start_line': 25, 'end_line': 26}, page_content='function `get_password_hash` in module `auth.routes`:\\n\\ndef get_password_hash(password: str) -> str:\\n    return pwd_context.hash(password)'), Document(metadata={'name': 'verify_password', 'type': 'function', 'file': 'routes.py', 'module': 'auth.routes', 'start_line': 28, 'end_line': 29}, page_content='function `verify_password` in module `auth.routes`:\\n\\ndef verify_password(plain_password: str, hashed_password: str) -> bool:\\n    return pwd_context.verify(plain_password, hashed_password)'), Document(metadata={'name': 'create_access_token', 'type': 'function', 'file': 'routes.py', 'module': 'auth.routes', 'start_line': 31, 'end_line': 35}, page_content='function `create_access_token` in module `auth.routes`:\\n\\ndef create_access_token(data: dict, expires_delta: timedelta | None = None) -> str:\\n    to_encode = data.copy()\\n    expire = datetime.utcnow() + (expires_delta or timedelta(minutes=15))\\n    to_encode.update({\"exp\": expire})\\n    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)'), Document(metadata={'name': 'signup', 'type': 'function', 'file': 'routes.py', 'module': 'auth.routes', 'start_line': 40, 'end_line': 59}, page_content='function `signup` in module `auth.routes`:\\n\\ndef signup(user: UserCreate, db: Session = Depends(get_db)):\\n    existing_user = db.query(DBUser).filter(DBUser.email == user.email).first()\\n    if existing_user:\\n        raise HTTPException(status_code=400, detail=\"Username already registered\")\\n\\n    hashed_password = get_password_hash(user.password)\\n    new_user = DBUser(\\n        username=user.username,\\n        email=user.email,\\n        hashed_password=hashed_password\\n    )\\n    db.add(new_user)\\n    db.commit()\\n    db.refresh(new_user)\\n\\n    access_token = create_access_token(\\n        data={\"sub\": new_user.username},\\n        expires_delta=timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)\\n    )\\n    return {\"access_token\": access_token, \"token_type\": \"bearer\"}'), Document(metadata={'name': 'login', 'type': 'function', 'file': 'routes.py', 'module': 'auth.routes', 'start_line': 63, 'end_line': 72}, page_content='function `login` in module `auth.routes`:\\n\\ndef login(user: UserLogin, db: Session = Depends(get_db)):\\n    db_user = db.query(DBUser).filter(DBUser.email == user.email).first()\\n    if not db_user or not verify_password(user.password, db_user.hashed_password):\\n        raise HTTPException(status_code=400, detail=\"Invalid credentials\")\\n\\n    access_token = create_access_token(\\n        data={\"sub\": db_user.username},\\n        expires_delta=timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)\\n    )\\n    return {\"access_token\": access_token, \"token_type\": \"bearer\"}'), Document(metadata={'name': 'protected_route', 'type': 'function', 'file': 'routes.py', 'module': 'auth.routes', 'start_line': 76, 'end_line': 77}, page_content='function `protected_route` in module `auth.routes`:\\n\\ndef protected_route(current_user: DBUser = Depends(get_current_user)):\\n    return {\"message\": f\"Hello, {current_user.username}. Middleware is working!\"}'), Document(metadata={'name': 'generate_topic', 'type': 'function', 'file': 'routes.py', 'module': 'auth.routes', 'start_line': 81, 'end_line': 120}, page_content='function `generate_topic` in module `auth.routes`:\\n\\ndef generate_topic(\\n    data: dict = Body(...),\\n    current_user: DBUser = Depends(get_current_user),\\n    db: Session = Depends(get_db)\\n):\\n    topic = data.get(\"topic\")\\n    if not topic:\\n        raise HTTPException(status_code=400, detail=\"Missing topic in request body\")\\n\\n    # Generate video (assuming this creates a temporary file)\\n    result = generate_and_execute_with_correction(prompt=topic)\\n    video_path = result.get(\"video_path\")\\n    \\n    if not video_path or not os.path.exists(video_path):\\n        raise HTTPException(status_code=404, detail=\"Generated video not found\")\\n\\n    # Upload to Supabase Storage\\n    file_key = f\"users/{current_user.id}/videos/{os.path.basename(video_path)}\"\\n    \\n    supabase.storage.from_(\"videos\").upload(file_key, video_path,\\n                                            {\"content-type\" : \"video/mp4\"})\\n    # Store metadata in DB\\n    video_record = Video(\\n        title=topic,\\n        scene_plan=result[\\'plan\\'],\\n        manim_code=result[\\'final_code\\'],\\n        video_path=file_key,  # Store path instead of binary\\n        owner=current_user\\n    )\\n    db.add(video_record)\\n    db.commit()\\n\\n    video_url = supabase.storage.from_(\"videos\").get_public_url(file_key)\\n\\n    return {\\n        \"title\": topic,\\n        \"scene_plan\": result[\\'plan\\'],\\n        \"video_url\": video_url,\\n        \"manim_code\": result[\\'final_code\\']\\n    }'), Document(metadata={'name': 'get_user_videos', 'type': 'function', 'file': 'routes.py', 'module': 'auth.routes', 'start_line': 124, 'end_line': 142}, page_content='function `get_user_videos` in module `auth.routes`:\\n\\ndef get_user_videos(\\n    current_user: DBUser = Depends(get_current_user),\\n    db: Session = Depends(get_db)\\n):\\n    videos = db.query(Video).filter(Video.user_id == current_user.id).all()\\n    \\n    response = []\\n    for video in videos:\\n        # Generate signed URL (expires in 1 hour)\\n        signed_url = supabase.storage.from_(\"videos\").get_public_url(video.video_path)\\n        \\n        response.append({\\n            \"title\": video.title,\\n            \"scene_plan\": video.scene_plan,\\n            \"video_url\": signed_url,\\n            \"manim_code\": video.manim_code\\n        })\\n    \\n    return response'), Document(metadata={'name': 'VideoBase', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 7, 'end_line': 11}, page_content='class `VideoBase` in module `auth.schemas`:\\n\\nclass VideoBase(BaseModel):\\n    title: str  # Added title field which was in your router but missing in schemas\\n    scene_plan: Optional[str] = None\\n    manim_code: Optional[str] = None\\n    video_path: Optional[str] = None  # Stores path in Supabase Storage instead of bytes'), Document(metadata={'name': 'VideoCreate', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 13, 'end_line': 15}, page_content='class `VideoCreate` in module `auth.schemas`:\\n\\nclass VideoCreate(VideoBase):\\n    \"\"\"For video creation (accepts file upload)\"\"\"\\n    pass  # File handling will be done in the endpoint, not via schema'), Document(metadata={'name': 'VideoResponse', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 17, 'end_line': 26}, page_content='class `VideoResponse` in module `auth.schemas`:\\n\\nclass VideoResponse(VideoBase):\\n    \"\"\"Response model with URL instead of binary data\"\"\"\\n    manim_code : str\\n    video_url: HttpUrl  # URL to access the video\\n    scene_plan : str\\n    title : str\\n\\n\\n    class Config:\\n        orm_mode = True'), Document(metadata={'name': 'UserBase', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 30, 'end_line': 32}, page_content='class `UserBase` in module `auth.schemas`:\\n\\nclass UserBase(BaseModel):\\n    username: str\\n    email: EmailStr'), Document(metadata={'name': 'UserLogin', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 34, 'end_line': 36}, page_content='class `UserLogin` in module `auth.schemas`:\\n\\nclass UserLogin(BaseModel):\\n    email: EmailStr\\n    password: str'), Document(metadata={'name': 'UserCreate', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 38, 'end_line': 39}, page_content='class `UserCreate` in module `auth.schemas`:\\n\\nclass UserCreate(UserBase):\\n    password: str'), Document(metadata={'name': 'UserResponse', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 41, 'end_line': 48}, page_content='class `UserResponse` in module `auth.schemas`:\\n\\nclass UserResponse(UserBase):\\n    \"\"\"Response model (never returns password)\"\"\"\\n    id: int\\n    created_at: datetime\\n    videos: List[VideoResponse] = []  # Now returns VideoResponse instead of Video\\n\\n    class Config:\\n        orm_mode = True'), Document(metadata={'name': 'Token', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 52, 'end_line': 54}, page_content='class `Token` in module `auth.schemas`:\\n\\nclass Token(BaseModel):\\n    access_token: str\\n    token_type: str'), Document(metadata={'name': 'TokenData', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 56, 'end_line': 57}, page_content='class `TokenData` in module `auth.schemas`:\\n\\nclass TokenData(BaseModel):\\n    username: Optional[str] = None'), Document(metadata={'name': 'Config', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 25, 'end_line': 26}, page_content='class `Config` in module `auth.schemas`:\\n\\n    class Config:\\n        orm_mode = True'), Document(metadata={'name': 'Config', 'type': 'class', 'file': 'schemas.py', 'module': 'auth.schemas', 'start_line': 47, 'end_line': 48}, page_content='class `Config` in module `auth.schemas`:\\n\\n    class Config:\\n        orm_mode = True'), Document(metadata={'name': 'hash_password', 'type': 'function', 'file': 'utils.py', 'module': 'auth.utils', 'start_line': 6, 'end_line': 7}, page_content='function `hash_password` in module `auth.utils`:\\n\\ndef hash_password(password: str):\\n    return pwd_context.hash(password)'), Document(metadata={'name': 'verify_password', 'type': 'function', 'file': 'utils.py', 'module': 'auth.utils', 'start_line': 9, 'end_line': 10}, page_content='function `verify_password` in module `auth.utils`:\\n\\ndef verify_password(plain_password, hashed_password):\\n    return pwd_context.verify(plain_password, hashed_password)'), Document(metadata={'name': 'ScenePlan', 'type': 'class', 'file': 'langchain.py', 'module': 'Model.langchain', 'start_line': 16, 'end_line': 18}, page_content='class `ScenePlan` in module `Model.langchain`:\\n\\nclass ScenePlan(BaseModel):\\n    scene : str = Field(description=\"Detailed plan for the animation\")\\n    scene_class_name : str = Field(description=\"Name of the scene class\")'), Document(metadata={'name': 'plan_scene', 'type': 'function', 'file': 'langchain.py', 'module': 'Model.langchain', 'start_line': 20, 'end_line': 80}, page_content='function `plan_scene` in module `Model.langchain`:\\n\\ndef plan_scene(prompt:str):\\n    system_prompt = \"\"\"\\n        You are a manim expert and an excellent teacher who can explain complex\\n        concepts in a clear and engaging way.\\n        You\\'ll be working with a manim developer who will write a manim script\\n        to render a video that explains the concept.\\n        Your task is to plan the scenes **NOT TO WRITE CODE** for a 30-60 second video using objects\\n        and animations that are feasible to execute using Manim.\\n        Break it down into few scenes, use the following guidelines:\\n\\n        INTRODUCTION AND EXPLANATION:\\n           - Introduce the concept with a clear title\\n           - Break down the concept into 2-3 key components\\n           - For each component, specify:\\n             * What visual elements to show (shapes, diagrams, etc.)\\n             * How they should move or transform\\n             * Exact narration text that syncs with the visuals\\n\\n        PRACTICAL EXAMPLE:\\n           - Show a concrete, relatable example of the concept\\n           - Demonstrate cause and effect or the process in action\\n           - Include interactive elements if possible\\n\\n        SUMMARY:\\n           - Recap the key points with visual reinforcement\\n           - Connect back to the introduction\\n\\n        CRITICALLY IMPORTANT:\\n        For EACH scene:\\n        - Ensure that the visual elements do not overlap or go out of the frame\\n        - The scene measures 8 units in height and 14 units in width.\\n        The origin is in the center of the scene, which means that, for example,\\n        the upper left corner of the scene has coordinates [-7, 4, 0].\\n        - Ensure that objects are aligned properly (e.g., if creating a pendulum,\\n        the circle should be centered at the end of the line segment and move together with it as a cohesive unit)\\n        - Ensure that the scene is not too crowded\\n        - Ensure that the explanations are scientifically accurate and pedagogically effective\\n        - Specify the visual elements to include\\n        - Specify the exact narration text\\n        - Specify the transitions between scenes\\n        - When specifying colors, you MUST ONLY use standard Manim color constants like:\\n        BLUE, RED, GREEN, YELLOW, PURPLE, ORANGE, PINK, WHITE, BLACK, GRAY, GOLD, TEAL\\n\\n    \"\"\"\\n    chat_prompt = ChatPromptTemplate([\\n        (\\'system\\' , system_prompt),\\n        (\"human\" ,\"Plan the scene for the following topic: {topic}\")\\n    ])\\n\\n    model = ChatGoogleGenerativeAI(\\n        model=\"gemini-2.0-flash\", \\n        temperature=0.8,\\n        google_api_key=geminikey\\n    )\\n    model = model.with_structured_output(ScenePlan)\\n\\n    chain = chat_prompt | model\\n    \\n    response = chain.invoke({\"topic\" : prompt})\\n\\n    return response'), Document(metadata={'name': 'ManimCodeResponse', 'type': 'class', 'file': 'langchain.py', 'module': 'Model.langchain', 'start_line': 82, 'end_line': 85}, page_content='class `ManimCodeResponse` in module `Model.langchain`:\\n\\nclass ManimCodeResponse(BaseModel):\\n    code:str = Field(description=\"Complete valid Python code for the animation\")\\n    explanation: Optional[str] = Field(None, description=\"Explanation of the code\")\\n    error_fixes: Optional[List[str]] = Field(None, description=\"Error fixes if any\")'), Document(metadata={'name': 'generate_code', 'type': 'function', 'file': 'langchain.py', 'module': 'Model.langchain', 'start_line': 87, 'end_line': 148}, page_content='function `generate_code` in module `Model.langchain`:\\n\\ndef generate_code(plan:str, scene_class_name:str) -> ManimCodeResponse:\\n    \"\"\"Generate a manim code from the plan\"\"\"\\n    system_prompt = f\"\"\"\\nYou are a Python expert and a professional Manim animation developer.\\n\\nYou will be given a detailed multi-scene visualization plan that includes:\\n- Scene titles and layout\\n- Visual elements (shapes, arrows, graphs, etc.)\\n- Descriptions of object placements and transformations\\n- Narration text that should sync with visuals\\n- Frame constraints and styling details\\n- Scene transitions\\n\\nYour task is to convert the described scenes into Python code using the Manim library (Community Edition), following these requirements:\\n\\n🟢 STRUCTURE:\\n- All scenes must be implemented within a **single class**, e.g., `class scene_class_name()`.\\n- Each logical scene should be a separate block inside the `construct()` method, with clear section comments like:\\n  `# Scene 1: Introduction`\\n\\n🟢 FUNCTIONALITY:\\n- Accurately place and animate all elements using Manim CE objects within a 14x8 unit frame\\n- Align visuals with narration using `.play()` and `.wait()` appropriately\\n- Display **narration text clearly on-screen** (centered at bottom or top) using `Text` or `MarkupText`\\n- Do **not tilt or rotate narration text** — keep it flat and readable and small in font \\n- You may fade in/out or transform narration text as scenes progress\\n- Use standard Manim classes only: `Text`, `MathTex`, `Circle`, `Line`, `Arrow`, `VGroup`, etc.\\n- Use only Manim color constants like `BLUE`, `YELLOW`, `RED`, etc.\\n- Ensure visuals are clean, not overlapping, and scientifically accurate\\n\\n🟢 IMPORTANT:\\n- Follow the scene plan exactly — do not invent or skip content\\n- For every narration segment:\\n  - Display the narration on screen as visible `Text`, centered and not angled (also run it as a form of subtitle removing old text then write new text on the bootom of screen)\\n  - Also include the narration as a **Python comment** in the code above that animation block\\n  - **DO NOT over zoom anywhere**\\n  - Use small font size to fit complete text on screen \\n  - heading should always be on top of screen\\n  - if you are using 3D Scenes and camera functions do not forget To inherit from base class ThreeDScene , MovingCameraScene\\n  - dont use longer sentences if you want to use longer sentence then break it two meaningful parts and show one below each other\\n-No need to use Voiceover\\n\\nOUTPUT: A single Python file, with one class and all scenes, ready to run in Manim.\\n\\n    \"\"\"\\n\\n    chat_prompt = ChatPromptTemplate.from_messages([\\n        (\"system\", system_prompt),\\n        (\"human\", \"Generate Manim code from this animation plan:\\\\n\\\\n{plan}\")\\n    ])\\n    messages = chat_prompt.format_messages(plan=plan)\\n\\n    model = ChatGoogleGenerativeAI(\\n        model=\"gemini-2.0-flash\", \\n        temperature=0.8,\\n        google_api_key=geminikey\\n    )\\n    model = model.with_structured_output(ManimCodeResponse) \\n\\n    response = model.invoke(messages)\\n\\n    return response'), Document(metadata={'name': 'ManimExecutionResponse', 'type': 'class', 'file': 'langchain.py', 'module': 'Model.langchain', 'start_line': 157, 'end_line': 160}, page_content='class `ManimExecutionResponse` in module `Model.langchain`:\\n\\nclass ManimExecutionResponse(BaseModel):\\n    output: str = Field(description=\"Output of the execution\")\\n    error: Optional[str] = Field(None, description=\"Error message\")\\n    video_path : Optional[str] = Field(None , description=\"Path of the file\")'), Document(metadata={'name': 'execute_manim_code', 'type': 'function', 'file': 'langchain.py', 'module': 'Model.langchain', 'start_line': 162, 'end_line': 207}, page_content='function `execute_manim_code` in module `Model.langchain`:\\n\\ndef execute_manim_code(code: str, scene_class_name: str) -> ManimExecutionResponse:\\n    # Save code to a .py file\\n    file_path = f\"{scene_class_name}.py\"\\n    with open(file_path, \"w\", encoding=\"utf-8\") as f:\\n        f.write(code)\\n\\n    print(f\" Saved code to: {os.path.abspath(file_path)}\")\\n    print(f\" Starting Manim rendering...\")\\n\\n    # Build manim command\\n    cmd = [\\n        \"python\", \"-m\", \"manim\",\\n        \"-pql\",  # Preview mode, low quality\\n        file_path,\\n        scene_class_name\\n    ]\\n\\n    # Run subprocess with correct encoding\\n    start_time = time.time()\\n    result = subprocess.run(\\n        cmd,\\n        capture_output=True,\\n        text=True,\\n        encoding=\\'utf-8\\',\\n        errors=\\'replace\\'  # Prevent UnicodeDecodeError\\n    )\\n    duration = time.time() - start_time\\n\\n    # Check result\\n    if result.returncode == 0:\\n        print(f\" Animation completed successfully in {duration:.1f} seconds!\")\\n\\n        # Locate output video\\n        video_files = glob.glob(f\"media/videos/{scene_class_name}/480p15/*.mp4\", recursive=True)\\n        if video_files:\\n            video_path = max(video_files, key=os.path.getctime)\\n            print(f\"📽️ Video saved to: {os.path.abspath(video_path)}\")\\n            print(\"🎬 Playing animation:\")\\n        else:\\n            print(\" Render completed but no video file was found.\")\\n        return ManimExecutionResponse(output=result.stdout , video_path=os.path.abspath(video_path))\\n    else:\\n        print(\" Animation failed to render.\")\\n        print(\"\\\\n--- Stdout ---\\\\n\", result.stdout)\\n        print(\"\\\\n--- Stderr ---\\\\n\", result.stderr)\\n        return ManimExecutionResponse(output=result.stdout, error=result.stderr)'), Document(metadata={'name': 'ManimErrorCorrectionResponse', 'type': 'class', 'file': 'langchain.py', 'module': 'Model.langchain', 'start_line': 209, 'end_line': 212}, page_content='class `ManimErrorCorrectionResponse` in module `Model.langchain`:\\n\\nclass ManimErrorCorrectionResponse(BaseModel): \\n    fixed_code: str = Field(...,description=\"The corrected Manim code that should resolve the errors\")\\n    explanation: str = Field(description=\"Explanation of what was fixed and why\")\\n    changes_made: List[str] = Field(description=\"List of specific changes made to fix the code\")'), Document(metadata={'name': 'correct_manim_errors', 'type': 'function', 'file': 'langchain.py', 'module': 'Model.langchain', 'start_line': 215, 'end_line': 283}, page_content='function `correct_manim_errors` in module `Model.langchain`:\\n\\ndef correct_manim_errors(code: str,error_message: str):\\n    \"\"\"\\n    Analyze Manim errors and generate fixed code.\\n\\n    Args:\\n        code: Original Manim code that produced errors\\n        error_message: Error output from the Manim execution\\n        scene_class_name: Name of the scene class\\n\\n    Returns:\\n        ManimErrorCorrectionResponse with fixed code and explanation\\n    \"\"\"\\n    system_prompt = \"\"\"\\n    You are an expert Manim developer and debugger. Your task is to fix errors in Manim code.\\n\\n    ANALYZE the error message carefully to identify the root cause of the problem.\\n    EXAMINE the code to find where the error occurs.\\n    FIX the issue with the minimal necessary changes.\\n\\n    Common Manim errors and solutions:\\n    1. \\'AttributeError: object has no attribute X\\' - Check if you\\'re using the correct method or property for that object type\\n    2. \\'ValueError: No coordinates specified\\' - Ensure all mobjects have positions when created or moved\\n    3. \\'ImportError: Cannot import name X\\' - Verify you\\'re using the correct import from the right module\\n    4. \\'TypeError: X() got an unexpected keyword argument Y\\' - Check parameter names and types\\n    5. \\'Animation X: 0%\\' followed by crash - Look for errors in animation setup or objects being animated\\n\\n    When fixing:\\n    - Preserve the overall structure and behavior of the animation\\n    - Ensure all objects are properly created and positioned\\n    - Check that all animations have proper timing and sequencing\\n    - Verify that voiceover sections have proper timing allocations\\n    - Maintain consistent naming and style throughout the code\\n\\n    Your response must include:\\n    1. The complete fixed code\\n    2. A clear explanation of what was wrong and how you fixed it\\n    3. A list of specific changes you made\\n    \"\"\"\\n\\n    chat_prompt = ChatPromptTemplate.from_messages([\\n        (\"system\", system_prompt),\\n        (\"human\", \"\"\"Please fix the errors in this Manim code.\\n\\n\\n            CODE WITH ERRORS:\\n            ```python\\n            {code}\\n            ```\\n\\n            ERROR MESSAGE:\\n            ```\\n            {error_message}\\n            ```\\n            Please provide a complete fixed version of the code, along with an explanation of what went wrong and how you fixed it.\\n            \"\"\"\\n        )\\n    ])\\n    messages = chat_prompt.format_messages(code = code , error_message = error_message)\\n\\n    model = ChatGoogleGenerativeAI(\\n        model=\"gemini-2.0-flash\", \\n        temperature=0.8,\\n        google_api_key=geminikey\\n    )\\n    model = model.with_structured_output(ManimErrorCorrectionResponse) \\n\\n    response = model.invoke(messages)\\n\\n    return response'), Document(metadata={'name': 'generate_and_execute_with_correction', 'type': 'function', 'file': 'langchain.py', 'module': 'Model.langchain', 'start_line': 286, 'end_line': 332}, page_content='function `generate_and_execute_with_correction` in module `Model.langchain`:\\n\\ndef generate_and_execute_with_correction(prompt: str, max_correction_attempts: int = 3):\\n    storyboard_response = plan_scene(prompt)\\n    scene_class_name = storyboard_response.scene_class_name\\n    print(f\" Scene planning complete: {scene_class_name}\")\\n\\n    # Step 2: Generate the code\\n    generated_code = generate_code(storyboard_response.scene, scene_class_name)\\n    current_code = generated_code.code\\n    print(\" Initial code generation complete\")\\n\\n    # Step 3: Execute with correction loop\\n    for attempt in range(max_correction_attempts + 1):\\n        if attempt > 0:\\n            print(f\"\\\\n Correction attempt {attempt}/{max_correction_attempts}...\")\\n\\n        # Execute current code\\n        result = execute_manim_code(current_code, scene_class_name)\\n\\n        # Check if execution succeeded\\n        if not result.error or \"Animation completed successfully\" in result.output:\\n            print(\" Animation executed successfully!\")\\n            break\\n\\n        # If we\\'ve reached max attempts, exit\\n        if attempt >= max_correction_attempts:\\n            print(f\" Failed to fix errors after {max_correction_attempts} attempts.\")\\n            break\\n\\n        # Try to fix the errors\\n        print(\"Errors detected, attempting to fix...\")\\n        correction = correct_manim_errors(current_code, result.error)\\n\\n        # Update the code for next attempt\\n        if correction == None:\\n            return None\\n        \\n        current_code = correction.fixed_code\\n\\n    # Return results\\n    return {\\n        \"scene_class_name\": scene_class_name,\\n        \"final_code\": current_code,\\n        \"plan\": storyboard_response.scene,\\n        \"execution_result\": result,\\n        \"correction_attempts\": attempt,\\n        \"video_path\" : result.video_path\\n    }')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def extract_functions_and_classes_from_code(code: str, file_path: str, module: str) -> List[Document]:\n",
    "    tree = ast.parse(code)\n",
    "    lines = code.splitlines()\n",
    "    chunks = []\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "            start_line = node.lineno - 1\n",
    "            end_line = node.end_lineno if hasattr(node, 'end_lineno') else start_line + 1\n",
    "            source = \"\\n\".join(lines[start_line:end_line])\n",
    "            name = node.name\n",
    "            kind = \"function\" if isinstance(node, ast.FunctionDef) else \"class\"\n",
    "            \n",
    "            # Add a helpful descriptive header to the chunk\n",
    "            enriched_content = f\"{kind} `{name}` in module `{module}`:\\n\\n{source}\"\n",
    "            doc = Document(\n",
    "                page_content=enriched_content,\n",
    "                metadata={\n",
    "                    \"name\": name,\n",
    "                    \"type\": kind,\n",
    "                    \"file\": os.path.basename(file_path),\n",
    "                    \"module\": module,\n",
    "                    \"start_line\": start_line + 1,\n",
    "                    \"end_line\": end_line\n",
    "                }\n",
    "            )\n",
    "            chunks.append(doc)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def path_to_module(repo_root: str, file_path: str) -> str:\n",
    "    rel_path = os.path.relpath(file_path, repo_root)\n",
    "    no_ext = os.path.splitext(rel_path)[0]\n",
    "    return no_ext.replace(os.sep, \".\")\n",
    "\n",
    "def crawl_repo(repo_path: str) -> List[Document]:\n",
    "    all_doc = []\n",
    "    for root, _, files in os.walk(repo_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".py\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        code = f.read()\n",
    "                        module = path_to_module(repo_path, full_path)\n",
    "                        all_doc.extend(extract_functions_and_classes_from_code(code, full_path, module))\n",
    "                except Exception as e:\n",
    "                    print(f\" Error parsing {file}: {e}\")\n",
    "    return all_doc\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"bge-code-v1\",  \n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")\n",
    "\n",
    "\n",
    "repo_path = \"repo\"  \n",
    "documents = crawl_repo(repo_path)\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chroma_dir = \"./chroma_db\"\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=chroma_dir\n",
    ")\n",
    "vectordb.persist()\n",
    "\n",
    "print(f\"✅ {len(documents)} chunks stored in Chroma at {chroma_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b295ceb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyanshu\\AppData\\Local\\Temp\\ipykernel_13356\\2453686522.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory= \"./chroma_db\",\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "retriever = vectordb.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"lambda_mult\" : 0.7\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "891afaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainFilter \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    disable_streaming=False,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],                    \n",
    ")\n",
    "\n",
    "base_retriever = vectordb.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"lambda_mult\": 0.7\n",
    "    }\n",
    ")\n",
    "\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=base_retriever,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "compressor = LLMChainFilter.from_llm(llm) \n",
    "\n",
    "combined_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=multi_query_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f0d3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91a0c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyanshu\\AppData\\Local\\Temp\\ipykernel_13356\\3706042611.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\",\n",
    "    input_key=\"query\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"query\", \"context\"],\n",
    "    template=\"\"\"\n",
    "You are a highly intelligent GitHub assistant.\n",
    "\n",
    "Conversation so far:\n",
    "{history}\n",
    "\n",
    "Relevant code context from the repository:\n",
    "{context}\n",
    "\n",
    "User question:\n",
    "{query}\n",
    "\n",
    "---\n",
    "\n",
    "Instructions:\n",
    "1. Begin with a direct answer.\n",
    "2. Then provide a detailed explanation using specific references to function names and file/modules (e.g., `auth.routes`, `auth.utils`).\n",
    "3. Use code blocks where helpful.\n",
    "4. If the feature is missing, respond: \"There is no such feature implemented in this repo.\"\n",
    "5. Suggest implementation ideas if possible.\n",
    "6. Use clear, structured formatting (markdown-friendly).\n",
    "\n",
    "Your Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "classifier_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "You are a classifier. Decide if this user query requires additional code context to answer.\n",
    "\n",
    "If the query is about a specific repo feature, implementation, or functionality, respond with \"yes\".\n",
    "If it's a casual question or memory-based (like follow-up or clarification), respond with \"no\".\n",
    "\n",
    "Query: {query}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "classifier_chain = LLMChain(llm=llm, prompt=classifier_prompt)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "\n",
    "def github_assistant_chat(query: str):\n",
    "    classification = classifier_chain.run(query).strip().lower()\n",
    "\n",
    "    if classification == \"yes\":\n",
    "        docs = combined_retriever.invoke(query)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    else:\n",
    "        context = \"\"\n",
    "\n",
    "    response = chain.run({\n",
    "        \"query\": query,\n",
    "        \"context\": context\n",
    "    })\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d642454",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(github_assistant_chat(\"How Manim Videos are generated in this repo ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd84a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(github_assistant_chat(\"Can you explain how scene planing is done ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c13588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I help you today?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--cff5b5d9-c4b2-47ad-a059-c1ba51982f99-0' usage_metadata={'input_tokens': 1, 'output_tokens': 10, 'total_tokens': 11, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4bf70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
